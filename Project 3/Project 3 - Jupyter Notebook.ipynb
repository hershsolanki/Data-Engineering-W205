{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First I will start with the entire Data pipeline (with documentation), and them my queries will be at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spin up the cluster:**\n",
    "    \n",
    "   \n",
    "```python\n",
    "docker-compose up -d    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run flask. Remember to call correct port number, and run the game API. This has the routes for both sword/guild. Go to the Game API python file to see my logic.**\n",
    "\n",
    "  ```python\n",
    "docker-compose exec mids \\\n",
    "  env FLASK_APP=/w205/project-3-honlineh/game_api.py \\\n",
    "  flask run --host 0.0.0.0\n",
    "```\n",
    "  \n",
    "Everytime an event is called, output looks as such. The 200 means it is a succesful event:\n",
    "\n",
    "127.0.0.1 - - [11/Dec/2019 22:30:14] \"GET /purchase_a_sword HTTP/1.0\" 200 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up Kafka Cat to watch for events:**\n",
    "    \n",
    "```python\n",
    "docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning\n",
    "    ```\n",
    "\n",
    "The output looks as such:\n",
    "\n",
    "{\"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\", \"discount\": \"No\", \"Host\": \"user1.comcast.com\",\"description\": \"Bronze\"}\n",
    "{\"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\", \"discount\": \"No\", \"Host\": \"user1.comcast.com\",\"description\": \"Bronze\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to get the two types of output above, we need to run some Apache Bench test data. This allows us to to generate data as if someone was playing the game.**\n",
    "\n",
    "To do so, we run:\n",
    "\n",
    "```python\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we peek into Hadoop to make sure that our sword purchase data is being stored:**\n",
    "    \n",
    "```python\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/purchases/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us start with Purchasing a Sword. We have to run the \"Write_Swords_Stream\" file. I have commented that file to mention what each parts does. Go to that file now. We use the following command to do so. Note we are NOT using Batch, we are only using Stream.**\n",
    "\n",
    "```python\n",
    "docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we go into Hive. Hive allows us to a create a table we can later query off, and allows us to keep track of various Schema we may need. I make sure to specify the Schema in the way I want it (with discount and sword type)**\n",
    "\n",
    "```python\n",
    "docker-compose exec cloudera hive\n",
    "```\n",
    "\n",
    "**Note how I add description and discount at the end**\n",
    "\n",
    "```python\n",
    "create external table if not exists default.sword_purchases (\n",
    "    raw_event string,\n",
    "    timestamp string,\n",
    "    Accept string,\n",
    "    Host string,\n",
    "    User_Agent string,\n",
    "    event_type string,\n",
    "    description string,\n",
    "    discount string\n",
    "  )\n",
    "  stored as parquet \n",
    "  location '/tmp/sword_purchases'\n",
    "  tblproperties (\"parquet.compress\"=\"SNAPPY\");\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, continously create data using Apache Bench every 10 seconds in an infinite while loop. I will use this to conduct some analytics later on in the report.**\n",
    "\n",
    "```python\n",
    "\n",
    "while true; do\n",
    "  docker-compose exec mids \\\n",
    "    ab -n 10 -H \"Host: user1.comcast.com\" \\\n",
    "      http://localhost:5000/purchase_a_sword\n",
    "  sleep 10\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I then fire up Presto for querying capabilities**\n",
    "\n",
    "```python\n",
    "docker-compose exec presto presto --server presto:8080 --catalog hive --schema default\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Within Presto, I can see which tables I have. At this point, I have created both the guild and sword table. Output is below.**\n",
    "\n",
    "```python\n",
    "show tables;\n",
    "```\n",
    "**As a result, we get:**\n",
    "```\n",
    "presto:default> show tables;\n",
    "      Table\n",
    "-----------------+\n",
    " join_guild\n",
    " sword_purchases\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also go into the schema of the swords table using:**\n",
    "    \n",
    "```\n",
    "describe sword_purchases;\n",
    "```\n",
    "\n",
    "**From this, we get:**\n",
    "    \n",
    "```\n",
    "   Column    |  Type   | Comment\n",
    "-------------+---------+---------\n",
    " raw_event   | varchar |\n",
    " timestamp   | varchar |\n",
    " accept      | varchar |\n",
    " host        | varchar |\n",
    " user_agent  | varchar |\n",
    " event_type  | varchar |\n",
    " description | varchar |\n",
    " discount    | varchar |\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before doing any actual querying that will give us some insights, we do some EDA. Specifically, I want to make sure that all the 8 fields have the proper values, as I did change the schema. Thus, we do the following:**\n",
    "\n",
    "```\n",
    "select Host from sword_purchases;\n",
    "\n",
    "select timestamp from sword_purchases;\n",
    "\n",
    "select * from sword_purchases;\n",
    "```\n",
    "\n",
    "Great, everything looks good! Table is populating nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Querying/Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "presto:default> select count(*) from sword_purchases;\n",
    " _col0\n",
    "-------+\n",
    "    20\n",
    "(1 row)\n",
    "\n",
    "##after 120 seconds\n",
    "\n",
    "presto:default> select count(*) from sword_purchases;\n",
    " _col0\n",
    "-------+\n",
    "   120\n",
    "(1 row)\n",
    "\n",
    "##after some more time\n",
    "\n",
    "presto:default> select count(*) from sword_purchases;\n",
    " _col0\n",
    "-------+\n",
    "   720\n",
    "(1 row)\n",
    "```\n",
    "I keep it growing until I hit 2020 entries. This is perhaphs the most vital part of the entire pipeline--because I see data being populated, and because my EDA checked out, I know my pipeline is giving me the desired results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We then run a couple queries on this table of ouput. As game creators, we have a rate of 1/5 for getting silver swords, and 1/25 of getting gold swords. We run a query to confirm this:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "presto:default> Select description, count(*) from sword_purchases group by description;\n",
    " description | _col1\n",
    "-------------+-------\n",
    " Bronze      |   1621\n",
    " Silver      |    315\n",
    " Gold        |     84\n",
    " ```\n",
    " \n",
    " Ultimately, we get 80% bronze, 16% Silver, and 4% Gold. From a business perspective, we can offer a higher amount of silver/gold values if the player pays for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also offer a discount for certain members, but this would be extremely lucky. A person has in a 1/100 chance of getting a discount on the sword. On the current dataset, we have the following distribution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "presto:default> Select discount, count(*) from sword_purchases group by discount;\n",
    " discount | _col1\n",
    "----------+-------\n",
    " No       |   2003\n",
    " Yes      |     17\n",
    " ```\n",
    " \n",
    "Here, we see the value of a discount to be 0.8%, which is below our expected 1%. We want to make sure there are not too many discounts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We then look at the lucky participants who get BOTH a gold sword and a discount on it. What a steal!! We as game developers need to make sure this doesn't happen often:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "presto:default> Select count(*) from sword_purchases where description = 'Gold' AND discount = 'Yes';\n",
    " _col1  \n",
    "----------+\n",
    " 3          \n",
    "```\n",
    "\n",
    "Indeed it only happens 3/2020, or 0.1485% of the time. If this happens too many times, the game would be \"broken\". From an exepcted value perspective, this should happen (1% * 4%) of the time - 0.04%. Though our sample size isn't the biggest, we are higher than where we expect to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can then run similar pieces of analysis on Join guild. This is ommitted due to repetition. I am including the similar queries to the ones I ran above for Swords:**\n",
    "\n",
    "Make sure joining guild produces proper response\n",
    "```python\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/join_guild\n",
    "```\n",
    "Running streaming file\n",
    "\n",
    "```python\n",
    "docker-compose exec spark spark-submit /w205/project-3-honlineh/write_guild_stream.py\n",
    "```\n",
    "\n",
    "The output looks like: \n",
    "{\"Accept\": \"*/*\", \"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"guild_type\": \"2\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Accept\": \"*/*\", \"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"guild_type\": \"1\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "\n",
    "Creating Hive table\n",
    "```python\n",
    "create external table if not exists default.join_guild (\n",
    "    raw_event string,\n",
    "    timestamp string,\n",
    "    Accept string,\n",
    "    Host string,\n",
    "    User_Agent string,\n",
    "    event_type string,\n",
    "    guild_type string\n",
    "  )\n",
    "  stored as parquet \n",
    "  location '/tmp/join_guild'\n",
    "  tblproperties (\"parquet.compress\"=\"SNAPPY\");\n",
    "``` \n",
    "Using presto to outlay schema \n",
    "```python\n",
    "describe join_guild;\n",
    "``` \n",
    "Seeing all the requests\n",
    "\n",
    "```python\n",
    "select * from join_guild;\n",
    "```\n",
    "\n",
    "Continously pushing additional data\n",
    "```python\n",
    "while true; do\n",
    "  docker-compose exec mids \\\n",
    "    ab -n 10 -H \"Host: user1.comcast.com\" \\\n",
    "      http://localhost:5000/join_guild\n",
    "  sleep 10\n",
    "done\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we shut down docker.**\n",
    "```\n",
    "docker-compose down\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
