    1  ps
    2  pswd
    3  sudo passwd hershsolanki
    4  df -h
    5  ls
    6  mkdir w205
    7  cd 205/
    8  cd w205/
    9  docker pull midsw205/base
   10  docker run -it --rm -v ~/w205:/w205 midsw205/base:latest bash
   11  git clone https://github.com/mids-w205-schioberg/course-content.git
   12  cd w205/
   13  man
   14  man curl
   15  ls -lah/root
   16  ls -lah /root
   17  sudo ls -lah /root
   18  curl -L -o annot_fpid.json https://goo.gl/qWiu7d
   19  curl -L -o lp_data.csv https://goo.gl/FDFPYB
   20  sudo usermod -aG sudo hershsolanki
   21  sudo apt update
   22  sudo apt install jq
   23  Y
   24  sudo apt install jq
   25  ls
   26  head lp_data.csv
   27  wc -l lp_data.csv
   28  head -n2 lp_data.csv
   29  cat lp_data.csv
   30  cat lp_data.csv | wc -l
   31  cat lp_data.csv | sort
   32  cat lp_data.csv | awk -F',' '{ print $2,$1 }' | sort
   33  cat annot_fpid.json | jq '.[][]' -r |  sort | uniq -c | sort -gr | head -10
   34  apt  install jq
   35  snap install jq  # version 1.5+dfsg-1, or
   36  sudo snap install jq  # version 1.5+dfsg-1, or
   37  cat annot_fpid.json | jq '.[][]' -r |  sort | uniq -c | sort -gr | head -10
   38  cat lp_data.csv | sort -n
   39  head annot_fpid.json 
   40  cat annot_fpid.json | jq . 
   41  cat annot_fpid.json | jq
   42  cat annot_fpid.json | jq '.[][]' -r
   43  cat annot_fpid.json | jq '.[][]' -r | sort
   44  cat annot_fpid.json | jq '.[][]' -r |  sort | uniq -c 
   45  cat annot_fpid.json | jq '.[][]' -r |  sort | uniq -c | sort -gr
   46  cat annot_fpid.json | jq '.[][]' -r |  sort | uniq -c | sort -gr | head -10
   47  bq query --use_legacy_sql=false '
   48  SELECT count(*)
   49  FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   50  bq query --use_legacy_sql=false '
   51  SELECT count(*)
   52  FROM `bigquery-public-data.san_francisco.bikeshare_stats`'
   53  bq query --use_legacy_sql=false 'SELECT count(*) FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   54  bq query --use_legacy_sql=false 'SELECT min(time), max(time) FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   55  '* SELECT MAX(TIME(end_date))
   56  * FROM `bigquery-public-data.san_francisco.bikeshare_tri
   57  bq query --use_legacy_sql=false '* SELECT MAX(TIME(end_date))
   58  * FROM `bigquery-public-data.san_francisco.bikeshare_trips` '
   59  bq query --use_legacy_sql=false 'SELECT MAX(TIME(end_date))
   60  * FROM `bigquery-public-data.san_francisco.bikeshare_trips` '
   61  bq query --use_legacy_sql=false 'SELECT MAX(TIME(end_date)) FROM `bigquery-public-data.san_francisco.bikeshare_trips` '
   62  bq query --use_legacy_sql=false 'SELECT count(distinct station_id) FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   63  cd w205/
   64  git clone https://github.com/mids-w205-schioberg/project-1-honlineh.git
   65  bq query --use_legacy_sql=false '
   66  SELECT count(*)
   67  FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   68  bq query --use_legacy_sql = false 'SELECT COUNT(*) FROM bigquery-public-data.san_francisco.bikeshare_trips'
   69  bq query --use_legacy_sql=false 'SELECT COUNT(*) FROM bigquery-public-data.san_francisco.bikeshare_trips'
   70  bq query --use_legacy_sql=false '
   71  SELECT count(*)
   72  FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   73  bq query --use_legacy_sql=false '
   74  SELECT count(*)
   75  FROM `bigquery-public-data.san_francisco.bikeshare_status
   76  bq query --use_legacy_sql=false '
   77  SELECT count(*)
   78  FROM `bigquery-public-data.san_francisco.bikeshare_status`'
   79  bq query --use_legacy_sql=false ' 
   80  SELECT MAX(TIME(end_date)) FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
   81  bq query --use_legacy_sql=false ' 
   82  SELECT COUNT(DISTINCT bike_number) FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
   83  bq query --use_legacy_sql=false ' 
   84  SELECT COUNT(*)
   85  FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
   86  WHERE Time(end_date) BETWEEN "00:00:00" AND "11:59:59"
   87  bq query --use_legacy_sql=false ' 
   88  SELECT count(*)
   89  FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
   90  WHERE Time(end_date) BETWEEN "00:00:00" AND "11:59:59"
   91  bq query --use_legacy_sql=false ' 
   92  SELECT count(*)
   93  FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
   94  WHERE Time(end_date) BETWEEN "00:00:00" AND "11:59:59"
   95  bq query --use_legacy_sql=false ' 
   96  SELECT count(*)
   97  FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
   98  WHERE Time(end_date) BETWEEN "00:00:00" AND "11:59:59"
   99  bq query --use_legacy_sql=false ' 
  100  SELECT count(*)
  101  FROM `bigquery-public-data.san_francisco.bikeshare_trips`
  102  WHERE Time(end_date) BETWEEN "00:00:00" AND "11:59:59”’
  103  bq query --use_legacy_sql=false ' 
  104  SELECT count(*)
  105  FROM `bigquery-public-data.san_francisco.bikeshare_trips`
  106  WHERE Time(end_date) BETWEEN "00:00:00" AND "11:59:59"'
  107  bq query --use_legacy_sql=false ' 
  108  SELECT COUNT(*)
  109  FROM `bigquery-public-data.san_francisco.bikeshare_trips` 
  110  WHERE Time(start_date) BETWEEN "12:00:00" AND "23:59:59"'
  111  docker ps
  112  docker ps -a
  113  pwd
  114  cd w205/
  115  pwd
  116  cd w205/
  117  docker run -it --rm -v ~/w205:/w205 midsw205/base bash
  118  docker run -it --rm -v ~/w205:/w205 midsw205/base bash pwd
  119  docker run -it --rm -v ~/w205:/w205 midsw205/base pwd
  120  docker run -it --rm -v ~/w205:/w205 midsw205/base bash
  121  ls
  122  cd project-1-honlineh
  123  git branch
  124  git branch first_try
  125  branch
  126  git branch
  127  git checkout first_try
  128  git branch
  129  vim README.md
  130  git commit -m "Don't forget to commit" README.md
  131  git config --global user.email "hersh@vimals.net
  132  git config --global user.email "hersh@vimals.net"
  133  git config --global user.name "Hersh Solanki"
  134  vim README.md
  135  git commit -m "Don't forget to commit" README.md
  136  git push origin first_try
  137  docker run redis
  138  docker ps
  139  docker run -d --name redis redis
  140  docker ps
  141  docker rm -f redis
  142  docker ps
  143  docker run -d --name redis -p 6379:6379 redis
  144  docker rm -f redis
  145  docker ps
  146  mkdir w205/redis-standalone
  147  cd /w205/redis-standalone
  148  cd w205/redis-standalone
  149  cp ../course-content/05-Storing-Data-II/example-0-docker-compose.yml docker-compose.yml
  150  docker-compose up -d
  151  docker-compose ps
  152  docker-compose logs redis
  153  ipython
  154  docker-compose down
  155  docker-compose ps
  156  docker ps
  157  cd /w205
  158  cd
  159  cd /w205
  160  cd w205
  161  mkdir redis-cluster
  162  cd redis-cluster/
  163  ls
  164  cp ../course-content/05-Storing-Data-II/example-1-docker-compose.yml docker-compose.yml
  165  ls
  166  docker-compose up -d
  167  docker-compose ps
  168  docker-compose logs redis
  169  docker-compose exec mids bash
  170  docker-compose down
  171  docker-compose ps
  172  bq query --use_legacy_sql=false ' SELECT COUNT(*)
  173  FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
  174  bq query --use_legacy_sql=false 'SELECT COUNT(DISTINCT bike_number)
  175  FROM `bigquery-public-data.san_francisco.bikeshare_trips`'
  176  w205
  177  cd w205
  178  ls
  179  cd project-1-honlineh
  180  git pull
  181  git commit
  182  ls
  183  git add 'Assignment 1 - W205.ipynb'
  184  git commit -m 'Assignment 1 - W205.ipynb'
  185  git push
  186  /w205
  187  cd /w205
  188  cs w205
  189  cd 2305
  190  cd w205
  191  ls
  192  cd project-1-honlineh
  193  ls
  194  git branch
  195  choco install MikTeX
  196  git branch
  197  git add 'Assignment 1 - W205.ipynb'
  198  git commit -m "Final" 'Assignment 1 - W205.ipynb'
  199  git push
  200  git push origin first_try
  201  git pull
  202  git add 'Assignment 1 - W205.ipynb'
  203  git commit -m "Final" 'Assignment 1 - W205.ipynb'
  204  ls
  205  git commit -m "final" 'Assignment 1 - W205.ipynb'
  206  git push origin first_try
  207  git pull
  208  git branch
  209  git pull
  210  git branch --set-upstream-to=origin/<branch> first_try
  211  git branch --set-upstream-to=origin/first_try
  212  git add 'Assignment 1 - W205.ipynb'
  213  git commit -m "final" 'Assignment 1 - W205.ipynb'
  214  git pull
  215  /w205
  216  cd w205
  217  ;s
  218  ls
  219  mkdir kafka
  220  cd kafka/
  221  cp ../course-content/06-Transforming-Data/docker-compose.yml
  222  cp ../..course-content/06-Transforming-Data/docker-compose.yml
  223  cp ../course-content/06-Transforming-Data/docker-compose.yml .
  224  docker-compose up -d
  225  docker-compose ps
  226  docker-compose logs zookeeper | grep -i binding
  227  docker-compose logs kafka | grep -i started
  228  docker-compose exec kafka kafka-topics --create --topic foo --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  229  docker-compose exec kafka kafka-topics --describe --topic foo --zookeeper zookeeper:32181
  230  docker-compose exec kafka bash -c "seq 42 | kafka-console-producer --request-required-acks 1 --broker-list localhost:29092 --topic foo && echo 'Produced 42 messages.'"
  231  docker-compose exec kafka kafka-console-consumer --bootstrap-server localhost:29092 --topic foo --from-beginning --max-messages 42
  232  curl -L -o github-example-large.json https://goo.gl/Y4MD58
  233  docker-compose exec mids bash -c "cat /w205/kafka/github-example-large.json | jq '.[]' -c"
  234  docker-compose exec mids bash -c "cat /w205/kafka/github-example-large.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t foo && echo 'Produced 100 messages.'"
  235  docker-compose exec kafka kafka-console-consumer --bootstrap-server kafka:29092 --topic foo --from-beginning --max-messages 42
  236  docker-compose exec mids bash -c "kafkacat -C -b kafka:29092 -t foo -o beginning -e" | wc -l
  237  docker-compose exec kafka kafka-topics --describe --topic foo --zookeeper zookeeper:32181
  238  docker-compose exec kafka kafka-topics --describe --topic bar --zookeeper zookeeper:32181
  239  docker-compose exec kafka kafka-topics --create --topic bar --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:3218
  240  docker-compose exec kafka kafka-topics --create --topic bar --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  241  docker-compose down
  242  history 
  243  seq 10
  244  docker ps
  245  mkdir ~/w205/spark-with-kafka
  246  cd ~/w205/spark-with-kafka
  247  cp ../course-content/07-Sourcing-Data/docker-compose.yml .
  248  vim docker-compose.yml
  249  docker-compose exec spark pyspark
  250  ç
  251  docker-compose up -d
  252  docker-compose exec kafka kafka-topics --create --topic foo --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  253  docker-compose exec kafka kafka-topics --describe --topic foo --zookeeper zookeeper:32181
  254  docker-compose exec kafka bash -c "seq 42 | kafka-console-producer --request-required-acks 1 --broker-list kafka:29092 --topic foo && echo 'Produced 42 messages.'"
  255  docker-compose exec spark pyspark
  256  docker-compose down
  257  curl -L -o github-example-large.json https://goo.gl/Y4MD58
  258  docker-compose up -d
  259  docker-compose exec kafka kafka-topics --create --topic foo --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  260  docker-compose exec kafka kafka-topics --describe --topic foo --zookeeper zookeeper:32181
  261  docker-compose exec spark pyspark
  262  curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp`
  263  docker-compose down
  264  docker-compose down
  265  curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp`
  266  curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp
  267  docker-compose up -d
  268  docker-compose logs -f kafka
  269  docker-compose exec kafka kafka-topics --create --topic foo --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  270  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/github-example-large.json | jq '.[]' -c"
  271  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c"
  272  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/assessment-attempts-20180128-121051-nested.json | jq '.[]' "
  273  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t foo && echo 'Produced 100 messages.
  274  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t foo && echo 'Produced 100 messages."
  275  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t foo && echo 'Produced 100 messages.
  276  docker-compose exec mids bash -c "cat /w205/spark-with-kafka/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t foo && echo 'Produced 100 messages.'"
  277  docker-compose exec spark pyspark
  278  docker-compose down
  279  cd w205/
  280  mkdir ~/w205/spark-with-kafka-and-hdfs
  281  cd ~/w205/spark-with-kafka-and-hdfs
  282  cp ~/w205/course-content//08-Querying-Data/docker-compose.yml .
  283  vim README
  284  curl -L -o players.json https://goo.gl/vsuCpZ
  285  vim players.json
  286  docker-compose up -d
  287  docker-compose ps
  288  docker-compose exec cloudera hadoop fs -ls /tmp/
  289  docker-compose exec kafka kafka-topics --create --topic players --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  290  docker-compose exec mids bash -c "cat /w205/<your_workspace>/players.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t players"
  291  docker-compose exec mids bash -c "cat /w205/spark-wtih-kafka-and-hdfs/players.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t players"
  292  docker-compose exec mids bash -c "cat /w205/spark-with-kafka-and-hdfs/players.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t players"
  293  docker-compose exec spark pyspark
  294  docker-compose exec cloudera hadoop fs -ls /tmp/
  295  cd w205
  296  cs spark-with-kafka-and-hdfs/
  297  cd spark-with-kafka-and-hdfs/
  298  docker-compose exec cloudera hadoop fs -ls /tmp/
  299  docker-compose exec cloudera hadoop fs -ls /tmp/players/
  300  docker-compose exec kafka kafka-topics --create --topic commits --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  301  curl -L -o github-example-large.json https://goo.gl/Y4MD58
  302  docker-compose exec mids bash -c "cat /w205/spark-with-kafka-and-hdfs/github-example-large.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t commits"
  303  docker-compose exec spark pyspark
  304  docker-compose exec cloudera hadoop fs -ls /tmp/
  305  w205
  306  cd w205
  307  cd project-2-honlineh
  308  docker-compose exec cloudera hadoop fs -ls /tmp/
  309  cd /w205
  310  cd w205
  311  cd spark-with-kafka-and-hdfs
  312  ls
  313  cd w205
  314  cd
  315  cd w205
  316  ls
  317  cd project-2-honlineh
  318  cp ~/w205/course-content//08-Querying-Data/docker-compose.yml .
  319  ls
  320  curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp
  321  ls
  322  docker-compose ps
  323  docker-compose up -d
  324  docker-compose exec cloudera hadoop fs -ls /tmp/
  325  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  326  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  327      | jq '.[]' -c \
  328      | kafkacat -P -b kafka:29092 -t assessments"
  329  docker-compose exec spark pyspark
  330  docker-compose exec mids curl http://localhost:5000/
  331  pwd
  332  cd 
  333  cd 205/flask-with-kafka
  334  cd 205
  335  cd w205
  336  cd flask-with-kafka
  337  docker-compose exec mids curl http://localhost:5000/
  338  docker-compose exec mids curl http://localhost:5000/purchase_a_sword
  339  ls
  340  docker-compose exec mids env FLASK_APP=/w205/flask-with-kafka/game_api.py flask run
  341  kill 5000
  342  kill$(lsof -t -i:5000)
  343  docker-compose exec mids env FLASK_APP=/w205/flask-with-kafka/game_api.py flask run
  344  lsof -i:5000
  345  docker-compose exec mids env FLASK_APP=/w205/flask-with-kafka/game_api.py flask run
  346  sudo lsof -t -i:5000
  347  docker-compose down
  348  git pul
  349  git pull
  350  cd w205
  351  mkdir flask-with-kafka
  352  cd flask-with-kafka
  353  cp../course-content/09-Ingesting-Data/*.py .
  354  cp~w205/course-content/09-Ingesting-Data/*.py .
  355  cp ~w205/course-content/09-Ingesting-Data/*.py .
  356  cp../course-content/09-Ingesting-Data/* .
  357  cp../course-content/09-Ingesting-Data/*py .
  358  cp../course-content/09-Ingesting-Data/*.py .
  359  cp ../course-content/09-Ingesting-Data/*.py .
  360  docker-compose up -d
  361  ls
  362  cp../course-content/09-Ingesting-Data/docker-compose.yml .
  363  cp ../course-content/09-Ingesting-Data/docker-compose.yml .
  364  ls
  365  docker-compose up -d
  366  vim basic_game_api.py
  367  docker-compose exec mids env FLASK_APP=/w205/flask-with-kafka/basic_game_api.py flask run
  368  cs w205
  369  cd w205
  370  ls
  371  cd project-2-honlineh
  372  ls
  373  history > test.txt
  374  docker-compose up -d
  375  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  376  docker-compose ps
  377  docker-compose exec kafka kafka-topics --create --topic assessments --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  378  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  379      | jq '.[]' -c \
  380      | kafkacat -P -b kafka:29092 -t assessments"
  381  docker-compose exec spark pyspark
  382  docker-compose down
  383  docker-compose ps
  384  docker-compose up -d
  385  docker-compose ps
  386  docker-compose logs -f kafka
  387  docker-compose exec cloudera hadoop fs -ls /tmp/
  388  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  389  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  390      | jq '.[]' -c \
  391      | kafkacat -P -b kafka:29092 -t assessments"
  392  docker-compose exec spark pyspark
  393  docker-compose down
  394  docker-compose up -d
  395  docker-compose ps
  396  docker-compose exec cloudera hadoop fs -ls /tmp/
  397  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  398  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  399      | jq '.[]' -c \
  400      | kafkacat -P -b kafka:29092 -t assessments"
  401  docker-compose exec spark pyspark
  402  docker-compose down
  403  w205
  404  cd w205
  405  cd project-2-honlineh
  406  docker-compose exec spark cat /root/.python_history
  407  docker-compose exec spark cat /project-2-honlineh/.python_history
  408  cd w205
  409  ls
  410  cd project-1-honlineh
  411  docker-compose up -d
  412  cd
  413  cd w205
  414  cd project-2-honlineh
  415  docker-compose up -d
  416  docker-compose exec spark cat /root/.python_history > python_history.txt
  417  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  418  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  419      | jq '.[]' -c \
  420      | kafkacat -P -b kafka:29092 -t assessments"
  421  docker-compose exec spark pyspark
  422  docker-compose exec spark cat /root/.python_history > python_history.txt
  423  docker-compose down
  424  cd w205
  425  ls
  426  cd project-2-honlineh
  427  docker-compose up -d
  428  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  429  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  430      | jq '.[]' -c \
  431      | kafkacat -P -b kafka:29092 -t assessments"
  432  docker-compose exec spark pyspark
  433  docker-compose exec spark cat /root/.python_history > python_history.txt
  434  docker-compose down
  435  W205
  436  cd w205
  437  cd project-2-honlineh
  438  docker-compose exec cloudera hadoop fs -ls /tmp/
  439  docker-compose exec cloudera hadoop fs -ls /tmp/commits/
  440  cd w205
  441  git clone https://github.com/mids-w205-schioberg/project-2-honlineh.git
  442  cd project-2-honlineh
  443  git add
  444  git add .
  445  git commit .
  446  git push
  447  history > <user-name>-history.txt
  448  history > hsolanki-history.txt
  449  git add .
  450  git commit .
  451  git push
  452  git branch
  453  git branch to-submit
  454  git branch
  455  git checkout to-submit
  456  git add .
  457  git commit .
  458  git add README.md
  459  git commit .
  460  git add *
  461  git commit -m "turning it in"
  462  git add README.md
  463  git status
  464  git add .
  465  git commit -m "turning it in"
  466  git add
  467  git add .
  468  git branch
  469  git add .
  470  git add README.md
  471  git add origin .
  472  git commit -a -m "new"
  473  git checkout master
  474  git checkout -b to-submit
  475  git checkout to-submit
  476  git add README.md
  477  git commit -m "Test"
  478  cd w205
  479  cd project-1-honlineh
  480  docker-compose up -d
  481  cd
  482  w 205
  483  cd w205
  484  cd project-2-honlineh
  485  docker-compose up -d
  486  ls
  487  vim docker-compose.yml
  488  docker-compose down
  489  vim docker-compose.yml
  490  docker-compose up -d
  491  docker-compose exec kafka   kafka-topics     --create     --topic assessments     --partitions 1     --replication-factor 1     --if-not-exists     --zookeeper zookeeper:32181
  492  docker-compose exec mids   bash -c "cat /w205/project-2-honlineh/assessment-attempts-20180128-121051-nested.json \
  493      | jq '.[]' -c \
  494      | kafkacat -P -b kafka:29092 -t assessments"
  495  docker-compose exec spark pyspark
  496  docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root' pyspark
  497  cd w205
  498  cd flask-with-kafka-and-spark
  499  docker-compose exec mids curl http://localhost:5000/purchase_a_sword
  500  docker-compose exec mids curl http://localhost:5000/
  501  docker-compose exec mids curl http://localhost:5000/purchase_a_sword
  502  docker-compose exec mids curl http://localhost:5000/purchase_a_frog
  503  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning -e
  504  cd course-content
  505  cd course-content/
  506  cd w205
  507  cd course-content/
  508  git pull
  509  cd
  510  cd w205
  511  cd flask-with-kafka
  512  docker pull midsw205/base:latest 
  513  docker pull midsw205/base:latest
  514  cd
  515  cd w205
  516  mkdir ~/w205/flask-with-kafka-and-spark/
  517  cd ~/w205/flask-with-kafka-and-spark/
  518  cp ~/w205/course-content/10-Transforming-Streaming-Data/docker-compose.yml .
  519  cp ~/w205/course-content/10-Transforming-Streaming-Data/*.py
  520  ls
  521  cp ~/w205/course-content/10-Transforming-Streaming-Data/* .py
  522  cp ~/w205/course-content/10-Transforming-Streaming-Data/*.py
  523  ls
  524  cp~/w205/course-content/10-Transforming-Streaming-Data/*.py
  525  cp ~/w205/course-content/10-Transforming-Streaming-Data/*.py
  526  ls
  527  cp ~/w205/course-content/10-Transforming-Streaming-Data/*.py .
  528  ls
  529  docker-compose up -d
  530  docker-compose exec kafka   kafka-topics     --create     --topic events     --partitions 1     --replication-factor 1     --if-not-exists --zookeeper zookeeper:32181
  531  docker-compose exec mids env FLASK_APP=/w205/flask-with-kafka-and-spark/game_api_with_json_events.py flask run --host 0.0.0.0
  532  vim game_api_with_json_events.py
  533  docker-compose exec mids env FLASK_APP=/w205/flask-with-kafka-and-spark/game_api_with_json_events.py flask run --host 0.0.0.0
  534  docker-compose exec spark pyspark
  535  docker-compose down
  536  cd w205
  537  mkdir spark-from-files
  538  cd spark-from-files
  539  cp ../course-content/11-Storing-Data-III/docker-compose.yml .
  540  cp ../course-content/11-Storing-Data-III/*.py .
  541  ls
  542  vim docker-compose.yml
  543  docker-compose up -d
  544  docker-compose logs -f cloudera
  545  docker-compose exec cloudera hadoop fs -ls /tmp/
  546  docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181
  547  vim game_api.py
  548  docker-compose exec mids env FLASK_APP=/w205/spark-from-files/game_api.py flask run --host 0.0.0.0
  549  docker-compose down
  550  cd w205
  551  cd spark-with-files
  552  cd spark-from-files
  553  docker-compose exec mids curl http://localhost:5000/purchase_a_sword
  554  docker-compose exec mids curl http://localhost:5000/
  555  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning -e
  556  ls
  557  vim extract_events.py
  558  docker-compose exec spark spark-submit /w205/spark-from-files/extract_events.py
  559  cp ../course-content/12-Querying-Data-II/*.py .
  560  vim just_filtering.py
  561  cd 205
  562  cd w205
  563  ls
  564  mkdir -p ~/w205/docker/mytools
  565  cd ~/w205/docker/mytools
  566  ls
  567  vim Dockerfile
  568  docker build -t mytools .
  569  docker images | grep mytools
  570  docker run -it --rm mytools bash
  571  docker compose down
  572  docker-compose down
  573  cd
  574  cdw05
  575  cd w205
  576  git clone https://github.com/mids-w205-schioberg/project-3-honlineh.git
  577  ls
  578  cd project-3-honlineh
  579  ls
  580  git checkout -b project3
  581  git add *
  582  git commit -m "Adding first lab"
  583  git push
  584  git push --set-upstream origin project3
  585  cp ~/w205/course-content/14-Patterns-for-Data-Pipelines/docker-compose.yml .
  586  cp ~/w205/course-content/14-Patterns-for-Data-Pipelines/*.py .
  587  ls
  588  docker-compose up -d
  589  docker-compose exec mids   env FLASK_APP=/w205/full-stack2/game_api.py   flask run --host 0.0.0.0
  590  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  591  cd w205
  592  cd project-3-honlineh/
  593  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  594  docker-compose ps
  595  cd w205
  596  ls
  597  cd project-3-honlineh/
  598  docker-compose ps
  599  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/
  600  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword
  601  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/
  602  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/purchase_a_sword
  603  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/join_guild
  604  ls
  605  cp ~/w205/course-content/13-Understanding-Data/*.py .
  606  ls
  607  docker-compose exec spark spark-submit /w205/full-stack2/filtered_writes.py
  608  docker-compose exec spark spark-submit /w205/project-3-honlineh/filtered_writes.py
  609  docker-compose exec cloudera hadoop fs -ls /tmp/purchases/
  610  docker-compose exec spark pyspark
  611  docker-compose exec cloudera hadoop fs -ls /tmp/purchases/
  612  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_hive_table.py
  613  docker-compose exec cloudera hadoop fs -ls /tmp/
  614  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  615  cd w205
  616  cd project-3-honlineh/
  617  docker-compose ps
  618  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  619  cd w205
  620  cd project-3-honlineh
  621  docker-compose exec spark spark-submit /w205/full-stack2/filter_swords_batch.py
  622  ls
  623  docker-compose exec spark spark-submit /w205/full-stack2/filter_swords_stream.py
  624  docker-compose exec spark spark-submit /w205/project-3-honlineh/filter_swords_stream.py
  625  docker-compose exec spark spark-submit /w205/full-stack2/write_swords_stream.py
  626  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  627  docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases
  628  docker-compose exec cloudera hive
  629  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  630  create external table if not exists default.sword_purchases (
  631  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  632  create external table if not exists default.sword_purchases (timestamp string, raw_event string, Accept string, Host string, User_Agent string, event_type string) stored as parquet location '/tmp/sword_purchases'  tblproperties ("parquet.compress"="SNAPPY");
  633  create external table if not exists default.sword_purchases (
  634  create external table if not exists default.sword_purchases (Accept string, Host string, User_Agent string, event_type string, timestamp string, raw_event string) stored as parquet location '/tmp/sword_purchases'  tblproperties ("parquet.compress"="SNAPPY");
  635  docker-compose exec cloudera hive
  636  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  637  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/
  638  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword
  639  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/
  640  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/purchase_a_sword
  641  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  642  docker-compose exec cloudera hive
  643  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  644  cd w205
  645  cd project-3-honlineh/
  646  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/
  647  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword
  648  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  649  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/
  650  docker-compose down
  651  cd w205
  652  cd project-3-honlineh/
  653  docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases
  654  docker-compose exec cloudera hive
  655  cd w205
  656  cd project-3-honlineh/
  657  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  658  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  659  cd w205
  660  cd project-3-honlineh/
  661  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  662  cd w205
  663  cd project-3-honlineh/
  664  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  665  docker-compose exec cloudera hive
  666  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  667  cd w205
  668  cd project-3-honlineh/
  669  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  670  while true; do docker-compose exec mids ab -n 10 -H "Host: user14.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  671  cd w205
  672  ls
  673  cd project-3-honlineh/
  674  docker-compose ps
  675  docker-compose up -d
  676  vim filter_swords_stream.py
  677  docker-compose exec spark spark-submit /w205/project-3-honlineh/filter_swords_stream.py
  678  vim write_swords_stream.py
  679  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  680  cd w205
  681  cd project-3-honlineh/
  682  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  683  docker-compose exec cloudera hive
  684  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  685  docker-compose exec cloudera hive
  686  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  687  cd w205
  688  cd project-3-honlineh/
  689  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  690  docker-compose exec mids   env FLASK_APP=/w205/full-stack2/game_api.py   flask run --host 0.0.0.0
  691  Run flask
  692  docker-compose exec mids   env FLASK_APP=/w205/project-3-honline/game_api.py   flask run --host 0.0.0.0
  693  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  694  docker-compose down
  695  cd w205
  696  cd project-3-honlineh/
  697  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/
  698  docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword
  699  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  700  docker-compose exec spark   env     PYSPARK_DRIVER_PYTHON=jupyter     PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root'   pyspark  
  701  docker-compose exec cloudera hive
  702  cd w205
  703  cd project-3-honlineh/
  704  docker-compose exec cloudera hive
  705  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  706  docker-compose exec cloudera hive
  707  cd w205
  708  cd project-3-honlineh/
  709  docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases
  710  docker-compose exec cloudera hive
  711  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  712  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  713  cd w205
  714  cd project-3-honlineh/
  715  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  716  cd w205
  717  cd project-3-honlineh/
  718  docker-compose ps
  719  docker-compose up -d
  720  docker-compose exec mids env FLASK_APP=/w205/full-streaming-stack/game_api.py flask run --host 0.0.0.0
  721  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  722  cd w205
  723  cd project-3-honlineh/
  724  docker-compose exec spark spark-submit /w205/full-streaming-stack/write_swords_stream.py
  725  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  726  cd w205
  727  cd project-3-honlineh/
  728  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  729  cd w205
  730  cd project-3-honlineh/
  731  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  732  cd w204
  733  cd w205
  734  cd project-3-honlineh/
  735  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  736  docker-compose exec cloudera hive
  737  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  738  cd w205
  739  cd project-3-honlineh/
  740  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  741  cd w205
  742  cd project-3-honlineh/
  743  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  744  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/join_guild; sleep 10; done
  745  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/join_guild
  746  cd w205
  747  cd project-3-honlineh/
  748  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  749  cd w205
  750  cd project-3-honlineh/
  751  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  752  cs
  753  cd w205
  754  cd project-3-honlineh/
  755  docker-compose down
  756  docker-compose up -d
  757  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  758  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  759  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  760  cd w205
  761  cd project-3-honlineh/
  762  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_swords_stream.py
  763  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_guild_stream.py
  764  cd w250
  765  cd w205
  766  cd project-3-honlineh/
  767  docker-compose up -d
  768  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py flask run --host 0.0.0.0
  769  docker-compose down
  770  cd
  771  cd w205
  772  docker-compose ps
  773  cd project-3-honlineh/
  774  docker-compose ps
  775  docker-compose up -d
  776  docker-compose exec midsenv FLASK_APP=/w205/project-3-honlineh/game_api.py flask run --host 0.0.0.0
  777  docker-compose ps
  778  docker-compose exec midsenv FLASK_APP=/w205/project-3-honlineh/game_api.py flask run --host 0.0.0.0
  779  cd w205
  780  cd project-3-honlineh/
  781  docker-compose exec spark spark-submit /w205/project-3-honlineh/write_guild_stream.py
  782  cd w205
  783  cd project-3-honlineh/
  784  docker-compose exec cloudera hive
  785  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  786  docker-compose exec cloudera hive
  787  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  788  cd w205
  789  cd project-3-honlineh/
  790  docker-compose exec mids ab -n 10 -H "Host: user2.att.com" http://localhost:5000/join_guild
  791  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/join_guild; sleep 10; done
  792  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  793  cd w205
  794  cd project-3-honlineh/
  795  docker-compose exec cloudera hive
  796  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  797  docker-compose exec cloudera hive
  798  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  799  docker-compose exec cloudera hive
  800  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  801  docker-compose exec cloudera hive
  802  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  803  docker-compose down
  804  docker-compose up -d
  805  docker-compose exec cloudera hive
  806  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  807  cd w205
  808  cd project-3-honlineh/
  809  docker-compose exec cloudera hive
  810  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  811  docker-compose exec cloudera hive
  812  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  813  docker-compose exec cloudera hive
  814  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  815  docker-compose down
  816  cd w205
  817  cd project-3-honlineh/
  818  docker-compose ps
  819  docker-compose up -d
  820  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  821  docker-compose down
  822  docker-compose up -d
  823  docker-compose exec mids   env FLASK_APP=/w205/project-3-honlineh/game_api.py   flask run --host 0.0.0.0
  824  cd w205
  825  cd project-3-honlineh/
  826  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  827  cd w205
  828  cd project-3-honlineh/
  829  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  830  cd
  831  cd w205
  832  cd project-3-honlineh/
  833  docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning
  834  cd w205
  835  cd project-3-honlineh/
  836  docker-compose exec midsenv FLASK_APP=/w205/project-3-honlineh/game_api.py flask run --host 0.0.0.0
  837  docker-compose down
  838  cd w205
  839  cd project-3-honlineh/
  840  docker-compose exec spark   env     PYSPARK_DRIVER_PYTHON=jupyter     PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root'   pyspark  
  841  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  842  docker-compose down
  843  cd w205
  844  cd project-3-honlineh/
  845  while true; do docker-compose exec mids ab -n 10 -H "Host: user1.comcast.com" http://localhost:5000/purchase_a_sword; sleep 10; done
  846  cd w2095
  847  cd w205
  848  cd project-3-honlineh/
  849  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  850  create external table if not exists default.sword_purchases (
  851  docker-compose exec cloudera hive
  852  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  853  docker-compose exec cloudera hive
  854  docker-compose exec presto presto --server presto:8080 --catalog hive --schema default
  855  history > hsolanki-history.txt
